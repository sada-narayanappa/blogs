{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<textarea rows=5 id=nav_head_content style=\"width:100%;display:none;\">\n",
       "<style>\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  ttext-decoration: none; \n",
       "  color: black;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size: 3em\n",
       "}\n",
       "</style>\n",
       "<!--\n",
       "<div id='HTMLTopBar' style=\"    \n",
       "    z-index: 50;\n",
       "    align-items: stretch;\n",
       "    width:100%\">\n",
       "    <div  style=\"\n",
       "        text-color: black;\n",
       "        background-color: #fefefe;\n",
       "        bborder-bottom: 1px dotted gray;\n",
       "        padding-left: 2px;\n",
       "        box-shadow: 5px 1px #ccc;\n",
       "        height: 40px; left: 0; \n",
       "        padding: 14px;\n",
       "        \"\n",
       "    >\n",
       "    <a class=bh1 href=\"#\" onclick=\"$('#maintoolbar').toggle();\">X</a>\n",
       "</div>\n",
       "-->\n",
       "</textarea>\n",
       "\n",
       "<script>\n",
       "if ($('#nav_head').length < 1) {\n",
       "    $('#notebook-container').prepend('<div id=\"nav_head\" style=\"width:100%;\">.</div>')\n",
       "    console.log(\"Added a div\")\n",
       "} else{\n",
       "    console.log(\"Already Added\")    \n",
       "}\n",
       "\n",
       "$('#nav_head').html($('#nav_head_content').val())\n",
       "\n",
       "$('.nbp-app-bar').toggle()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');\n",
       "</style>\n",
       "<style>\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "body  p ol li {\n",
       "    font-family: \"Roboto\",  \"Lucida Grande\", \"Lucida Sans Unicode\";\n",
       "    font-size: 14px;\n",
       "    background: #fff\n",
       "}\n",
       "\n",
       "h1, h2, h3{\n",
       "    font-family: 'Roboto', sans-serif;\n",
       "}\n",
       "div#notebook_panel div#notebook{\n",
       "    background: #ffffff\n",
       "}\n",
       "div#notebook-container{\n",
       "    box-shadow: 0px;\n",
       "    padding: 0px;\n",
       "    border-left: .05em dotted gray;\n",
       "    -webkit-box-shadow: 0px;\n",
       "    box-shadow: none;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width: 100% !important; }\n",
       "    div.cell{\n",
       "        width:100%;\n",
       "        margin-left:0%;\n",
       "        margin-right:auto;\n",
       "}\n",
       ".CodeMirror {\n",
       "    font-family: monospace;\n",
       "}\n",
       "div.input_area {\n",
       "    border: 0px;\n",
       "}\n",
       "div.cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       ".cell.selected{\n",
       "  border: '0px';\n",
       "}\n",
       "div#notebook{\n",
       "    padding-top: 0px;\n",
       "}\n",
       "div.prompt_container {\n",
       "    display: block; \n",
       "    background: #f7f7f7;\n",
       "}\n",
       "div.prompt{\n",
       "    min-width:0px;\n",
       "    display: grid;\n",
       "}\n",
       "div.cell{\n",
       "    padding-bottom: 5px;\n",
       "    padding-left: 0px;\n",
       "}\n",
       "\n",
       "a.bh,  a.bh:visited, a.bh:link, a.bh:active {\n",
       "  text-decoration: none; \n",
       "  color:white;\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  font-size:1em\n",
       "}\n",
       "a.bh:hover {\n",
       "  color: #ffccdd;\n",
       "}\n",
       "\n",
       "a.bh1,  a.bh1:visited, a.bh1:link, a.bh1:active {\n",
       "  text-decoration: none; \n",
       "  color: rgba(0, 0, 0, 0.87);\n",
       "  font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "  padding-right: 30px;\n",
       "  font-size:1.1em\n",
       "}\n",
       "a.bh1:hover {\n",
       "  color: rgba(0, 0, 0, 0.57);\n",
       "}\n",
       "    \n",
       "#toc-wrapper {\n",
       "   font-family: 'Roboto','Heebo',Arial,sans-serif;\n",
       "    border: 0px dotted gray;\n",
       "    padding: 10px;\n",
       "    line-height: 1.8em;\n",
       "}    \n",
       "</style>\n",
       "<script>\n",
       "l=\"https://www.ancient-symbols.com/images/wp-image-library/fullsize/infinity.jpg\"\n",
       "l=\"imgs/logo.png\"\n",
       "l=\"\"\n",
       "$('#ipython_notebook').html(`<img src=\"${l}\">`)\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom\n",
    "\n",
    "import os, sys, datetime, re, json, importlib\n",
    "from collections import defaultdict\n",
    "from sys import modules\n",
    "from IPython.display import HTML, Javascript\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "pd.set_option('display.max_rows', 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /opt/utils/getraw.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /opt/utils/getraw.py\n",
    "#!/usr/local/bin/python \n",
    "\n",
    "import os, sys\n",
    "import tika\n",
    "tika.TikaClientOnly = True\n",
    "from tika import parser\n",
    "import base64\n",
    "import textract\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getDataTika(ffile):\n",
    "    data = parser.from_file(ffile)\n",
    "    text = data['content'].strip() if 'content' in data and data['content'] else None\n",
    "    return text;\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getDataFromRaw(ffile, maxsize=5*1024*1024):\n",
    "    size = os.path.getsize(ffile)\n",
    "    if (size > maxsize):\n",
    "        print(f\"File size is too large {size/1024/2014}MB; max is {maxsize}\")\n",
    "        return ffile, ffile\n",
    "                \n",
    "    with open(ffile, \"rb\") as f:\n",
    "        raw =f.read();\n",
    "    try:\n",
    "        data = base64.b64encode(raw).decode('ascii')\n",
    "    except:\n",
    "        data = \"\"\n",
    "    return (data);\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getDataTExtract(ffile):\n",
    "    text = textract.process(ffile)\n",
    "    return text\n",
    "            \n",
    "    return None;\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getData(ffile):\n",
    "    text = f\"ERROR: Unable to read from {ffile}\"\n",
    "    try:\n",
    "        text = getDataTExtract(ffile)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        #print(f'Error Textract: {e}')\n",
    "        pass;\n",
    "    \n",
    "    try:\n",
    "        text = getDataTika(ffile)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f'Error Tika: {e}')\n",
    "\n",
    "    return text;\n",
    "#-----------------------------------------------------------------------------------\n",
    "def split_paragraph(text, max_paragraph_size = 512):\n",
    "    documents = [text]\n",
    "    \n",
    "    if (len(text) <= max_paragraph_size):\n",
    "        return documents\n",
    "    \n",
    "    paras = [f.strip() for f in re.split(r'[\\n\\r][\\n\\r]+', test) if f]\n",
    "\n",
    "    if ( not paras ):\n",
    "        return documents;\n",
    "    \n",
    "    documents = []\n",
    "    last_para = \"\"\n",
    "    for para in paras:\n",
    "        para = para.strip()\n",
    "        if not para:\n",
    "            continue\n",
    "        if not last_para:\n",
    "            last_para = para\n",
    "            continue;\n",
    "            \n",
    "            \n",
    "        if len(last_para) < max_paragraph_size and (len(para) < 10 or len(re.findall(r\"\\s+\", para)) < 2):\n",
    "            last_para += \"\\n\"+para\n",
    "        else:\n",
    "            documents.append(last_para)\n",
    "            last_para = para\n",
    "            \n",
    "    if ( last_para):\n",
    "        documents.append(last_para)\n",
    "    \n",
    "    return documents\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "def inJupyter():\n",
    "    try:    get_ipython; return True\n",
    "    except: return False\n",
    "if __name__ == '__main__':\n",
    "    if ( not inJupyter()):\n",
    "        if (len(sys.argv) <= 1):\n",
    "            print(\"No arguments? give file name\")\n",
    "            sys.exit(1)\n",
    "        file = os.path.expanduser(sys.argv[1])\n",
    "        data = getData(file)   \n",
    "        print(f'''{data[0:512]}''')\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "#getData(os.path.expanduser(\"~/Downloads/test.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /opt/utils/filestoes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /opt/utils/filestoes.py\n",
    "#!/usr/local/bin/python \n",
    "\n",
    "import sys, os, datetime, getopt, math,  json, argparse, glob, elasticsearch\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import base64, pathlib\n",
    "import getraw\n",
    "\n",
    "'''\n",
    "*** NOTE: DO NOT EDIT THIS FILE - THIS iS CREATED FROM: aiservices/notebooks/es/loadtoelastic.ipynb\n",
    "Indexes all the files into elastic search - currently running on local machine\n",
    "'''\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getfile(file_name, index='', split_paragraphs=False, **kwargs):\n",
    "\n",
    "    ext = pathlib.Path(file_name).suffix[1:]\n",
    "\n",
    "    if ( ext in \"md meta csv txt\".split()):\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            contents =f.read();        \n",
    "    else:\n",
    "        contents = getraw.getData(file_name)\n",
    "        \n",
    "    if (not type(contents) == str):\n",
    "        contents = contents.decode('ascii', 'ignore')\n",
    "\n",
    "    meta ={}\n",
    "    fmeta= file_name+\".meta\"\n",
    "    \n",
    "    if (os.path.exists(fmeta)):\n",
    "        with open(fmeta, \"rb\") as f:\n",
    "            cmeta =f.read();        \n",
    "            meta = json.loads(cmeta)\n",
    "        \n",
    "    contents = contents.strip()\n",
    "    if ( not contents ):\n",
    "        print(f\"No data in {file_name}\")\n",
    "        return None;\n",
    "\n",
    "    #We can use this if storing abspath is dangerous\n",
    "    #id1 = \"\".join([f'{i:03}' for i in \"/cikiosk/notebooks/sada\".encode()])\n",
    "    #OR\n",
    "    #id1 = Hash(\"/cikiosk/notebooks/sada\")\n",
    "\n",
    "    ftype = pathlib.Path(file_name).suffix[1:]\n",
    "    rfile_name = file_name\n",
    "    if (ftype == \"meta\"):\n",
    "        rfile_name = file_name[:-5]  # Remote \".meta extension\"\n",
    "        \n",
    "    id1     = os.path.abspath(rfile_name)\n",
    "    id1     = id1.encode('ascii', 'ignore').decode()    \n",
    "    size    = os.path.getsize(rfile_name)\n",
    "    stats   = os.stat( rfile_name )\n",
    "    docType = pathlib.Path(rfile_name).suffix[1:] or \"_doc\"\n",
    "    doc_source = {\n",
    "        \"file_name\"  : rfile_name,\n",
    "        \"id\"         : id1,\n",
    "        \"full_path\"  : id1,\n",
    "        \"public\"     : \"on\",\n",
    "        \"approved\"   : 0,\n",
    "        \"comments\"   : {'id': 0, \"comment\": \"\", \"time\": \"\", 'rating': \"\"},\n",
    "        \"author\"     : meta.get(\"user\", ''),\n",
    "        \"index\"      : index,\n",
    "        \"editors\"    : meta.get(\"collaborators\", ''),\n",
    "        \"type\"       : docType,\n",
    "        \"create_time\": datetime.datetime.fromtimestamp(stats.st_mtime),\n",
    "        \"modify_time\": datetime.datetime.fromtimestamp(stats.st_mtime),\n",
    "        \"content\"    : contents,\n",
    "        'rev'        : 1.0, \n",
    "        'votesup'    : 0,\n",
    "        'votesdown'  : 0,\n",
    "        \"rating\"     : 0,\n",
    "        \"score\"      : 0\n",
    "    }\n",
    "    if (ftype == \"meta\"):\n",
    "        d1 =json.loads(contents)\n",
    "        doc_source.update(d1)\n",
    "        os.rename(file_name, f'{file_name}.1')\n",
    "\n",
    "    op = {\n",
    "        \"_index\": doc_source['index'],\n",
    "        #\"_type\" : docType,\n",
    "        \"_id\": id1, # number _id for each iteration\n",
    "        \"_source\": doc_source\n",
    "    }\n",
    "    \n",
    "    print(f\"File:{id1} {len(contents)} type: {docType} {index}\")\n",
    "    return op\n",
    "#-----------------------------------------------------------------------------------\n",
    "def _yield_files():\n",
    "    ppath = sysargs.path+\"/\"+sysargs.pattern\n",
    "    if ( sysargs.recurse ):\n",
    "        ppath = sysargs.path+\"/**/\"+sysargs.pattern\n",
    "        \n",
    "    #files = glob.glob(ppath)\n",
    "    files = [f for f in glob.glob(ppath, recursive=sysargs.recurse) if os.path.isfile(f)]\n",
    "    print (f'Path: {ppath}, R: {sysargs.recurse}, files:({len(files)}): {files[0:5]} ... ')\n",
    "    return files\n",
    "\n",
    "def yield_docs():\n",
    "    files = _yield_files()\n",
    "    count = 0\n",
    "\n",
    "    for ffile in files:\n",
    "        if ( count >= sysargs.number):\n",
    "            return count;\n",
    "        \n",
    "        #If already indexed - dont index it again\n",
    "        indexed = f'{ffile}.mdd'; \n",
    "        if os.path.exists( indexed):\n",
    "            print(f\"-Ignoring {indexed} exists\")\n",
    "            continue;\n",
    "        \n",
    "        #ddir = os.path.dirname(ffile)+\"/indexed\"\n",
    "        #if (not os.path.exists(ddir)): os.mkdir(ddir)\n",
    "        if ( sysargs.pattern != \"*.meta\" and (ffile.endswith(\"meta\") or ffile.endswith(\"mdd\")) ):\n",
    "            print(f\"-Ignoring {ffile} because of no explicit pattern. Call with 't \\*.meta'\")\n",
    "            continue;\n",
    "        \n",
    "        print(f\"+Indexing {ffile}\")\n",
    "        try:\n",
    "            count += 1\n",
    "            op= getfile(ffile, sysargs.index, sysargs.paras)\n",
    "            if (not op):\n",
    "                continue;\n",
    "            with open (indexed, \"w\") as f: f.write(\"\")\n",
    "            yield op\n",
    "        except Exception as e:\n",
    "            print(f\"*** ERROR *** {ffile} {e}\")\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "def deleteAll(es=None):\n",
    "    if not es:\n",
    "        es = Elasticsearch([{'host': sysargs.host, 'port': sysargs.port}])\n",
    "    \n",
    "    k=[k for k in es.indices.get_alias('*').keys()]\n",
    "    for i in k:\n",
    "        print(f'deleteing {i}')\n",
    "        es.indices.delete(index=i)\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "def createSome(es=None):\n",
    "    if not es:\n",
    "        es = Elasticsearch([{'host': sysargs.host, 'port': sysargs.port}])\n",
    "    es.index(index='internal', doc_type = 'internal', id=1, body={\n",
    "        'rev':1.1,\n",
    "        'type': 'report',\n",
    "        'author': 'Boeing Martin',\n",
    "        'title': 'LM airplane better than boeing airplane',\n",
    "        'topics': ['airplane', 'engine', 'lockheed', 'boeing', 'pilot'],\n",
    "        'link': 'linktoactualreport',\n",
    "        'content': 'we can put actual text from the body of the document here',\n",
    "        'priority': 1\n",
    "    })        \n",
    "#-----------------------------------------------------------------------------------    \n",
    "def main():\n",
    "    print(f'''Will start to index files from directory {sysargs.path} - {sysargs.verify} ''')\n",
    "    \n",
    "    if (sysargs.verify):\n",
    "        v = input(\"is this OK? (Y/n):\")\n",
    "        if ( v.lower() == 'n'):\n",
    "            print(\"User aborting ...\")\n",
    "            return \n",
    "\n",
    "    es = Elasticsearch([{'host': sysargs.host, 'port': sysargs.port}])\n",
    "    \n",
    "    try:\n",
    "        #_yield_files()\n",
    "        resp = helpers.bulk( es, yield_docs())\n",
    "        print (\"\\nhelpers.bulk() RESPONSE:\", resp)\n",
    "    except Exception as err:\n",
    "        print(\"\\nhelpers.bulk() ERROR:\", err)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs=None\n",
    "desc = '''\n",
    "This program will index files from a directory into elastic search.\n",
    "Make sure you install and configure elastic search. When ready to index files, change to that directory \n",
    "and run:\n",
    "\\n\\n\n",
    "\n",
    "    filestoes.py -t \"*.meta\" \n",
    "\n",
    "'''\n",
    "def addargs():\n",
    "    sysargs = None\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\", description=desc)\n",
    "    p.add_argument('-H', '--host',   type=str,             required=False, default=\"localhost\", help=\"host\"                 )\n",
    "    p.add_argument('-p', '--port',   type=int,             required=False, default=9200,        help=\"ES port number\"       )\n",
    "    p.add_argument('-d', '--path',   type=str,             required=False, default=\".\",         help=\"directory of files\"   )\n",
    "    p.add_argument('-i', '--index',  type=str,             required=False, default=\"aiml\",      help=\"Index Name\"           )\n",
    "    p.add_argument('-n', '--number', type=int,             required=False, default=1024*1024,   help=\"Max files to index\"   )\n",
    "    p.add_argument('-s', '--skip',   type=int,             required=False, default=0,           help=\"skip # of files\"      )\n",
    "    p.add_argument('-t', '--pattern',type=str,             required=False, default=\"*.*\",       help=\"File patterns\"        )\n",
    "    p.add_argument('-f', '--force',  action='store_true',  required=False, default=False,       help=\"Reindex \"             )\n",
    "    p.add_argument('-a', '--attach', type=bool,            required=False, default=True,        help=\"As Attachment\"        )\n",
    "    p.add_argument('-x', '--maxsize',type=int,             required=False, default=5*1024*1024, help=\"Maxsize\"              )\n",
    "    p.add_argument('-P', '--paras'  ,action='store_true',  required=False, default=False,       help=\"Split text to paras\"  )\n",
    "    p.add_argument('-R', '--recurse',action='store_true',  required=False, default=False,       help=\"recurse\"  )\n",
    "    p.add_argument('-v', '--verify', action='store_true',  required=False, default=False,       help=\"Verify\"   )\n",
    "    p.add_argument('-D', '--delete', action='store_true',  required=False, default=False,       help=\"**DELETE INDICES**\"   )\n",
    "    p.add_argument('-C', '--create', action='store_true',  required=False, default=False,       help=\"**Create random stuff\")\n",
    "    p.add_argument('files',nargs='*')\n",
    "\n",
    "    try:\n",
    "        sysargs=p.parse_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "\n",
    "    return sysargs\n",
    "#-----------------------------------------------------------------------------------\n",
    "def inJupyter():\n",
    "    try:    get_ipython; return True\n",
    "    except: return False\n",
    "if __name__ == '__main__':\n",
    "    if ( not inJupyter()):\n",
    "        t1 = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        \n",
    "        if ( sysargs.delete ):\n",
    "            deleteAll()\n",
    "        elif ( sysargs.create ):\n",
    "            createSome()\n",
    "        else:\n",
    "            main()\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"{sys.argv[0]}: All Done in {str(t2-t1)} ***\")\n",
    "    else: \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#-----------------------------------------------------------------------------------\\ndef createPipeline(es, index):\\n    body = {\\n      \"description\" : \"Extract attachment information\",\\n      \"processors\" : [\\n        {\\n          \"attachment\" : {\\n            \"field\" : \"data\"\\n          }\\n        }\\n      ]\\n    }\\n    ret = es.index(index=\\'_ingest\\', doc_type=\\'pipeline\\', id=\\'attachment\\', body=body)\\n    return ret;\\n\\n#-----------------------------------------------------------------------------------\\ndef IndexFile(es, id, body, index=\\'internal\\', doc_type=\"_doc\"):\\n    result2 = es.index( index=index, doc_type=doc_type, pipeline=pipe, id = id1, body=body)\\n    return result2;\\n\\n#-----------------------------------------------------------------------------------\\ndef IndexDirFiles1(es, rootdir, index, docType=\"\", force=0, howmany=1024*1024):\\n    count = 0\\n    for subdir, dirs, files in os.walk(rootdir):\\n        for file in files:\\n            if ( count >= howmany):\\n                return count;\\n            ffile= os.path.join(subdir, file)\\n            \\n            #We can use this if storing abspath is dangerous\\n            #id1 = \"\".join([f\\'{i:03}\\' for i in \"/cikiosk/notebooks/sada\".encode()])\\n            #OR\\n            #id1 = Hash(\"/cikiosk/notebooks/sada\")\\n            \\n            indexed = f\"indexed/{ffile}\"\\n            if ffile.endswith(\"indexed\") or os.path.exists(indexed):\\n                continue;\\n                \\n            id1 = os.path.abspath(ffile)\\n            id1 = id1.encode(\\'ascii\\', \\'ignore\\').decode()\\n                \\n            try:\\n                text = getraw.getData(ffile)\\n                text = text.decode(\\'ascii\\', \\'ignore\\')\\n            except Exception as e:\\n                print(f\"{Exception: {ffile} : {e}}\")\\n                continue;\\n                \\n            if ( not text ):\\n                print(\"No data\")\\n                continue\\n                \\n            try:\\n                size = os.path.getsize(ffile)\\n                if not sysargs.attach or size > sysargs.maxsize:\\n                    attach = \"\"\\n                else:\\n                    with open(ffile, \"rb\") as f:\\n                        raw =f.read();\\n                        attach = base64.b64encode(raw).decode(\\'ascii\\')\\n                \\n                body = {\\'data\\': attach, \\'text\\': text, \\'rev\\': 1.0, \\'votes\\': 1.0, \\'id\\': id1 }\\n                \\n                docType = pathlib.Path(ffile).suffix[1:] or \"notype\"\\n                \\n                print(f\"File:{id1} count: {count}/{howmany}, {len(text)} type: {docType} {index}\")\\n                result2 = IndexFile(es, body, index, docType, id1, pipe=\"attachment\")\\n                count += 1\\n                \\n                if ( not os.path.exists(\"indexed\")):\\n                    print(\"Creating directory indexed\")\\n                    os.makedir(\"indexed\")\\n                with open(\"indexed/\"+ffile+\".indexed\", \"w\") as f:\\n                    pass;\\n                #if (move(os.path.abspath(ffile), os.path.abspath(ffile)+\".indexed\")):\\n                #    od.move(\"\")\\n            except Exception as e:\\n                print(e)\\n                return;\\n    \\n        if sysargs.recurse:\\n            for d in dirs:\\n                if ( d.endswith(\"indexed\")):\\n                    continue;\\n                IndexDirFiles(es, os.path.join(subdir, d), index, docType, force, howmany, recurse)\\n                count += 1\\n        return count;\\n            \\n#-----------------------------------------------------------------------------------\\ndef main1():\\n    print(f\\'Will start to index files from directory {sysargs.path} - \\')\\n    v = input(\"is this OK? (y/N):\")\\n    if ( v.lower() == \\'n\\'):\\n        print(\"User aborting ...\")\\n        return \\n    es = Elasticsearch([{\\'host\\': sysargs.host, \\'port\\': sysargs.port}])\\n    createPipeline(es, sysargs.index);\\n    c = IndexDirFiles1(es, sysargs.path, sysargs.index) \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile /opt/utils/filestoes-OLD.py\n",
    "#!/usr/local/bin/python \n",
    "'''\n",
    "#-----------------------------------------------------------------------------------\n",
    "def createPipeline(es, index):\n",
    "    body = {\n",
    "      \"description\" : \"Extract attachment information\",\n",
    "      \"processors\" : [\n",
    "        {\n",
    "          \"attachment\" : {\n",
    "            \"field\" : \"data\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ret = es.index(index='_ingest', doc_type='pipeline', id='attachment', body=body)\n",
    "    return ret;\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def IndexFile(es, id, body, index='internal', doc_type=\"_doc\"):\n",
    "    result2 = es.index( index=index, doc_type=doc_type, pipeline=pipe, id = id1, body=body)\n",
    "    return result2;\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def IndexDirFiles1(es, rootdir, index, docType=\"\", force=0, howmany=1024*1024):\n",
    "    count = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if ( count >= howmany):\n",
    "                return count;\n",
    "            ffile= os.path.join(subdir, file)\n",
    "            \n",
    "            #We can use this if storing abspath is dangerous\n",
    "            #id1 = \"\".join([f'{i:03}' for i in \"/cikiosk/notebooks/sada\".encode()])\n",
    "            #OR\n",
    "            #id1 = Hash(\"/cikiosk/notebooks/sada\")\n",
    "            \n",
    "            indexed = f\"indexed/{ffile}\"\n",
    "            if ffile.endswith(\"indexed\") or os.path.exists(indexed):\n",
    "                continue;\n",
    "                \n",
    "            id1 = os.path.abspath(ffile)\n",
    "            id1 = id1.encode('ascii', 'ignore').decode()\n",
    "                \n",
    "            try:\n",
    "                text = getraw.getData(ffile)\n",
    "                text = text.decode('ascii', 'ignore')\n",
    "            except Exception as e:\n",
    "                print(f\"{Exception: {ffile} : {e}}\")\n",
    "                continue;\n",
    "                \n",
    "            if ( not text ):\n",
    "                print(\"No data\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                size = os.path.getsize(ffile)\n",
    "                if not sysargs.attach or size > sysargs.maxsize:\n",
    "                    attach = \"\"\n",
    "                else:\n",
    "                    with open(ffile, \"rb\") as f:\n",
    "                        raw =f.read();\n",
    "                        attach = base64.b64encode(raw).decode('ascii')\n",
    "                \n",
    "                body = {'data': attach, 'text': text, 'rev': 1.0, 'votes': 1.0, 'id': id1 }\n",
    "                \n",
    "                docType = pathlib.Path(ffile).suffix[1:] or \"notype\"\n",
    "                \n",
    "                print(f\"File:{id1} count: {count}/{howmany}, {len(text)} type: {docType} {index}\")\n",
    "                result2 = IndexFile(es, body, index, docType, id1, pipe=\"attachment\")\n",
    "                count += 1\n",
    "                \n",
    "                if ( not os.path.exists(\"indexed\")):\n",
    "                    print(\"Creating directory indexed\")\n",
    "                    os.makedir(\"indexed\")\n",
    "                with open(\"indexed/\"+ffile+\".indexed\", \"w\") as f:\n",
    "                    pass;\n",
    "                #if (move(os.path.abspath(ffile), os.path.abspath(ffile)+\".indexed\")):\n",
    "                #    od.move(\"\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return;\n",
    "    \n",
    "        if sysargs.recurse:\n",
    "            for d in dirs:\n",
    "                if ( d.endswith(\"indexed\")):\n",
    "                    continue;\n",
    "                IndexDirFiles(es, os.path.join(subdir, d), index, docType, force, howmany, recurse)\n",
    "                count += 1\n",
    "        return count;\n",
    "            \n",
    "#-----------------------------------------------------------------------------------\n",
    "def main1():\n",
    "    print(f'Will start to index files from directory {sysargs.path} - ')\n",
    "    v = input(\"is this OK? (y/N):\")\n",
    "    if ( v.lower() == 'n'):\n",
    "        print(\"User aborting ...\")\n",
    "        return \n",
    "    es = Elasticsearch([{'host': sysargs.host, 'port': sysargs.port}])\n",
    "    createPipeline(es, sysargs.index);\n",
    "    c = IndexDirFiles1(es, sysargs.path, sysargs.index) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bumm bu ...\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "f=\"files.csv\"\n",
    "ext=pathlib.Path(f).suffix[1:]\n",
    "\n",
    "if ( ext in \"md meta csv txt\".split()):\n",
    "    print(\"Bumm bu ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sada\n",
      "New Line\n",
      "sdsadsa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "f='''\n",
    "sada\n",
    "baby, sds sfsf\n",
    "sdsadsa\n",
    "'''\n",
    "\n",
    "n= re.sub('\\nbaby.*\\n', \"\\nNew Line\\n\", f)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
